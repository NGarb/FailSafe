{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac3a1b4f-0b93-4382-8d1b-16d310f8f66f",
   "metadata": {},
   "source": [
    "# in this notebook, we start doing some intelligent optimization:\n",
    "namely: https://towardsdatascience.com/doing-xgboost-hyper-parameter-tuning-the-smart-way-part-1-of-2-f6d255a45dde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b21635-8697-4b98-985f-770dfecfac36",
   "metadata": {},
   "source": [
    "the article compares three different parameter tuning techniques: \n",
    "1. grid-search\n",
    "2. coordinate descent  \n",
    "3. genetic algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69b3d9d-4e08-4382-ac1d-5d20323145e9",
   "metadata": {},
   "source": [
    "\"For practical reasons and to avoid the complexities involved in doing hybrid continuous-discrete optimization, most approaches to hyper-parameter tuning start off by discretizing the ranges of all hyper-parameters in question. For example, for our XGBoost experiments below we will fine-tune five hyperparameters. The ranges of possible values that we will consider for each are as follows:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdddf5f-9388-4b22-853b-bff5ec03a5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] , #personally, starting to get a bit of a feel for ranges. small datasets are going to have much smaller learning rates be more effective, while large dataset will typically benefit from more trees combined with a larger learning rate\n",
    " \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    " \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    " \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    " \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ] }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2ea2d3-58e1-492e-8f89-f69bdadad14f",
   "metadata": {},
   "source": [
    "## GRID SEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06abed71-0b7e-4e70-b425-a8f2290e0a87",
   "metadata": {},
   "source": [
    "Exhaustive brute force search sweeping all parameter combinations. The article rightly states that lexicogrphic-ordered parameter search is not recommended because it will just get stuck in random areas of the search space, this is not very efficient and is actually like a buzzhead way of doing it. Instead, the author says that randomly searching the whole grid-space is preferable. \"With this type of search, it is likely that one encounters close-to-optimal regions of the hyper-param space early on. We show some evidence of this in the example below.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed00489-351e-49ed-ad4b-c6663fdf0d3b",
   "metadata": {},
   "source": [
    "## COORDINATE DESCENT \n",
    "Simpler than gradient descent :D\n",
    "\"The basic idea is that, at each iteration, only one of the coordinate directions of our search vector h is altered. To pick which one, we examine each coordinate direction turn and minimize the objective function by varying that coordinate and leaving all the other constant. Then we pick the direction that yields the most improvement. The algorithm stops when none of the directions yields any improvement.\"\n",
    "Very easy to understand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b28042-2746-4894-8904-4f2a599f2f21",
   "metadata": {},
   "source": [
    "## GENETIC ALGO\n",
    "Genetic algorithms (GAs) are a whole class of optimization algorithms of rather general applicability and are particularly well adapted for high-dimensional discrete search spaces. A genetic algorithm tries to mimic nature by simulating a population of feasible solutions to a(n optimization) problem as they evolve through several generations and survival of the fittest is enforced. There are two basic mechanisms for generating a new generation from the previous one. One is cross-breeding in which two individuals (feasible solutions) are combined to produce two offspring. The other one is mutation. With a given mutation probability, any individual can change any of their params to another valid value. Survival of the fittest is enforced by letting fitter individuals cross-breed with higher probability than less fit individuals. The fitness of an individual is of course the negative of the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "121982c2-d57f-4613-a71d-77ee40932d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://en.wikipedia.org/wiki/Coordinate_descent\n",
    "#https://github.com/infoyuxiglobal/data-analytics/blob/master/hpar_opt_experiments/coordescent.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b8e4ab-e055-46fe-82d7-3bfe37e207e1",
   "metadata": {},
   "source": [
    "all code at https://github.com/infoyuxiglobal/data-analytics/tree/master/hpar_opt_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4521761-46ff-41a4-8a0e-2901c4d53d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('D:/Projects/Re-education/Optimization/hpar_opt_experiments/')\n",
    "\n",
    "from collections import OrderedDict\n",
    "from itertools import product\n",
    "import random\n",
    "import xgboost as xgb\n",
    "import os\n",
    "from importlib import reload\n",
    "\n",
    "import pandas as pd\n",
    "#import xgboost as xgb\n",
    "#%%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from memoize import Memoizer\n",
    "from inst_func_eval import InstFunEvaluator\n",
    "from hashlib import md5\n",
    "\n",
    "import genetic\n",
    "os.chdir('D:/Projects/Prediction/Techniques Practice/Trees/XGBoost/Suicides/temp data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "750a6b93-28db-4479-9d53-9e4ee1184624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65d8455d-cbec-48de-91c2-26e02a322bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('D:/Projects/Prediction/Techniques Practice/Trees/XGBoost/Suicides/temp data/X_train.csv').drop('Unnamed: 0',axis=1)\n",
    "y_train = pd.read_csv('D:/Projects/Prediction/Techniques Practice/Trees/XGBoost/Suicides/temp data/y_train.csv').drop('Unnamed: 0',axis=1).values\n",
    "X_val = pd.read_csv('D:/Projects/Prediction/Techniques Practice/Trees/XGBoost/Suicides/temp data/X_val.csv').drop('Unnamed: 0',axis=1)\n",
    "y_val = pd.read_csv('D:/Projects/Prediction/Techniques Practice/Trees/XGBoost/Suicides/temp data/y_val.csv').drop('Unnamed: 0',axis=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "772ab8eb-7fe8-47af-8e74-6464568ec486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def main() :\n",
    "    \n",
    "    param_grid_dic = OrderedDict([\n",
    "            (\"learning_rate\", [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ),\n",
    "            (\"max_depth\"    , [  3 , 4 , 5, 6,  8, 10, 12, 15 ] ),\n",
    "            (\"min_child_weight\", [ 1, 3, 5, 7 ] ),\n",
    "            (\"gamma\", [0.0, 0.1, 0.2, 0.3, 0.4 ]),\n",
    "            (\"colsample_bytree\", [  0.3, 0.4, 0.5, 0.7 ] ),\n",
    "            ])\n",
    "\n",
    "    #%%\n",
    "    train_fraction = 0.05\n",
    "    test_fraction = 0.16\n",
    "    #data = subsample( data0, train_fraction, test_fraction )\n",
    "    data=None\n",
    "    #%%\n",
    "    seed=1359\n",
    "    log_level=0\n",
    "    #%%\n",
    "    memoization_path = DATA_DIR + \"/\" + \"xgboost_memo%g\" % train_fraction\n",
    "    print( \"memoization_path= \" + memoization_path)\n",
    "    if not os.path.exists( memoization_path ) :\n",
    "        os.mkdir( memoization_path )\n",
    "    #%%\n",
    "    fun = Memoizer( lambda param_dic : train_xgb( data, param_dic ),\n",
    "                    memoization_path )\n",
    "    #%%\n",
    "    grid_search( param_grid_dic, fun )\n",
    "    #%%\n",
    "\n",
    "\n",
    "def run_trials( n_trials, param_grid_dic, fun, method, method_name ) :\n",
    "\n",
    "    for i in range(n_trials) :\n",
    "        print( \"trial = %d\" % i )\n",
    "        fun_eval = method( param_grid_dic, fun, seed=i )\n",
    "\n",
    "def grid_search( param_grid_dic, fun, seed, log_level=0 ) :\n",
    "    #%%\n",
    "    import inst_func_eval as ife\n",
    "    from hashlib import md5\n",
    "\n",
    "    param_combos_shuffled = make_param_combos( param_grid_dic, seed=seed)\n",
    "\n",
    "    best_auc = 0\n",
    "    #best_combo = None\n",
    "\n",
    "    fun_eval = ife.InstFunEvaluator( fun, param_grid_dic )\n",
    "\n",
    "    for i, param_dic  in enumerate( param_combos_shuffled ) :\n",
    "        \n",
    "        auc = fun_eval.eval_fun(fun, param_dic )\n",
    "        if log_level > 0 :\n",
    "            print( tuple( param_dic.items() )  )\n",
    "            print( auc,  \" best_auc: \", best_auc  )\n",
    "        if auc > best_auc :\n",
    "            best_auc = auc\n",
    "            #best_combo = param_dic\n",
    "\n",
    "    #%%\n",
    "    return fun_eval\n",
    "\n",
    "\n",
    "def coordinate_descent( param_grid_dic, fun, seed=1359 ) :\n",
    "    #%%\n",
    "    import coordescent as cd\n",
    "    reload(cd)\n",
    "\n",
    "    #param_grid = param_grid_dic.values()\n",
    "\n",
    "    fun_min = lambda param_dic : -fun(param_dic)\n",
    "\n",
    "    random.seed( seed  )\n",
    "\n",
    "    best_val, best_idxs, fun_eval = cd.coordinate_descent( fun_min, param_grid_dic, x_idxs=None)\n",
    "    #%%\n",
    "    return fun_eval\n",
    "    #%%\n",
    "def genetic( param_grid_dic, fun, seed=1336 ) :\n",
    "    #%%\n",
    "    from importlib import reload\n",
    "    import genetic as G\n",
    "    reload( G )\n",
    "\n",
    "    genes_grid = param_grid_dic\n",
    "\n",
    "    best_val, best_idxs, fun_eval  = G.genetic_algorithm( fun,  genes_grid,\n",
    "                                       init_pop = None, pop_size = 10, n_gen=30,\n",
    "                                       mutation_prob=0.1,\n",
    "                                       normalize = G.normalizer( 2.0, 0.01),\n",
    "                                       seed=seed )\n",
    "\n",
    "    # Params first batch\n",
    "    #best_val, best_idxs, fun_eval  = G.genetic_algorithm( fun,  genes_grid,\n",
    "    #                                   init_pop = None, pop_size = 30, n_gen=10,\n",
    "    #                                   mutation_prob=0.1,\n",
    "    #                                   normalize = G.normalizer( 2.0, 0.01),\n",
    "    #                                   seed=seed )\n",
    "\n",
    "    #print( best_val, fun_eval.eval_cnt() )\n",
    "    #%%\n",
    "    return fun_eval\n",
    "    #%% 0.7407\n",
    "    #_ = G.genetic_algorithm( fun, gene_names, genes_grid,\n",
    "    #                                 init_pop = None, pop_size = 30, n_gen=10,\n",
    "    #                                 mutation_prob=0.2,\n",
    "    #                                 #normalize = g.normalizer( 1.0, 0.3),\n",
    "    #                                 seed=1337 )\n",
    "    #%%\n",
    "\n",
    "\n",
    "def test( data, memoization_path ) :\n",
    "    #%%\n",
    "    param_dic = OrderedDict([('learning_rate', 0.2),\n",
    "             ('max_depth', 5),\n",
    "             ('min_child_weight', 1),\n",
    "             ('gamma', 0.4),\n",
    "             ('colsample_bytree', 0.7)])\n",
    "\n",
    "\n",
    "    train_xgb( data, param_dic, memoization_path=None, model_type='xgb')\n",
    "\n",
    "    #%%\n",
    "\n",
    "def subsample( data0, train_fraction, test_fraction, seed=1337 ) :\n",
    "    data = data0.copy()\n",
    "    n_train = len(data0[\"x_train\"])\n",
    "    assert n_train== len(data0[\"y_train\"])\n",
    "    #%%\n",
    "    np.random.seed( seed )\n",
    "    r = np.random.rand(n_train) < train_fraction\n",
    "    data[\"x_train\"] = data0[\"x_train\"].loc[r]\n",
    "    data[\"y_train\"] = data0[\"y_train\"].loc[r]\n",
    "\n",
    "    #%%\n",
    "    np.random.seed( seed )\n",
    "    n_test= len( data0[\"x_test\"])\n",
    "    assert n_test == len(data0[\"y_test\"])\n",
    "\n",
    "    r = np.random.rand(n_test) < test_fraction\n",
    "\n",
    "    data[\"x_test\"] = data0[\"x_test\"].loc[r]\n",
    "    data[\"y_test\"] = data0[\"y_test\"].loc[r]\n",
    "    #%%\n",
    "    return data\n",
    "\n",
    "\n",
    "def make_param_combos( param_grid_dic, seed=1337 ) :\n",
    "    #param_lens = [ len(v) for v  in param_grid_dic.values() ]\n",
    "    param_names = list( param_grid_dic.keys() )\n",
    "\n",
    "    param_idx_ranges = [ range(len(v)) for v in param_grid_dic.values() ]\n",
    "    all_param_idx_combos = product( *param_idx_ranges  )\n",
    "    all_param_combos = [  OrderedDict( ( name, param_grid_dic[name][idx])\n",
    "                                for name, idx in  zip(param_names,idx_combo ) )\n",
    "                          for idx_combo in all_param_idx_combos   ]\n",
    "    #%%\n",
    "    np.random.seed( seed )\n",
    "    param_combos_shuffled = all_param_combos.copy()\n",
    "    np.random.shuffle( param_combos_shuffled )\n",
    "    #%%\n",
    "    return param_combos_shuffled\n",
    "\n",
    "#%%\n",
    "\n",
    "def train_xgb(param_dic, model_type='xgb' ) :\n",
    "    # fit model no training data\n",
    "\n",
    "    if model_type == 'xgb' :\n",
    "        model = xgb.XGBRegressor( learning_rate=param_dic[\"learning_rate\"],\n",
    "                                   max_depth=param_dic[\"max_depth\"],\n",
    "                                   min_child_weight=param_dic[\"min_child_weight\"],\n",
    "                                   colsample_bytree=param_dic[\"colsample_bytree\"],\n",
    "                                   gamma=param_dic[\"gamma\"],\n",
    "                                   tree_method = \"gpu_hist\",\n",
    "                                   single_precision_histogram=True, \n",
    "                                   gpu_id=0 )\n",
    "    else :\n",
    "        model = RandomForestClassifier( n_estimators=100, min_samples_split=50, min_samples_leaf=10, max_depth=12)\n",
    "    print( type(model) )\n",
    "    model.fit(X_train, y_train )\n",
    "\n",
    "    y_pred = model.predict_proba( X_val )[:,1]\n",
    "    rmse = np.sqrt(mse( y_val, y_pred ))\n",
    "    #\n",
    "    return rmse\n",
    "#%%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649e747e-e1b2-4a3f-92de-ceb988cf862c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f661465b-c761-49c0-8c56-7f7e03f029ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xgboost.sklearn.XGBRegressor'>\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "Invalid Parameter format for colsample_bytree expect float but value='[0.3, 0.4, 0.5, 0.7]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_36056/2220702776.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmemoization_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDATA_DIR\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"xgboost_memo%g\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#fun = Memoizer( lambda param_dic : train_xgb( param_dic ), memoization_path )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMemoizer\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtrain_xgb\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mparam_grid_dic\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemoization_path\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m param_grid_dic = OrderedDict([\n\u001b[0;32m      6\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[1;34m\"learning_rate\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.30\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_36056/2678448463.py\u001b[0m in \u001b[0;36mtrain_xgb\u001b[1;34m(param_dic, model_type)\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX_val\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_configure_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m         self._Booster = train(\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \"\"\"\n\u001b[1;32m--> 188\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    189\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1680\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1681\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1682\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \"\"\"\n\u001b[0;32m    217\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: Invalid Parameter format for colsample_bytree expect float but value='[0.3, 0.4, 0.5, 0.7]'"
     ]
    }
   ],
   "source": [
    "DATA_DIR = r\".\"\n",
    "memoization_path = DATA_DIR + \"/\" + \"xgboost_memo%g\" \n",
    "#fun = Memoizer( lambda param_dic : train_xgb( param_dic ), memoization_path )\n",
    "fun = Memoizer( train_xgb( param_grid_dic ), memoization_path )\n",
    "param_grid_dic = OrderedDict([\n",
    "            (\"learning_rate\", [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ),\n",
    "            (\"max_depth\"    , [  3 , 4 , 5, 6,  8, 10, 12, 15 ] ),\n",
    "            (\"min_child_weight\", [ 1, 3, 5, 7 ] ),\n",
    "            (\"gamma\", [0.0, 0.1, 0.2, 0.3, 0.4 ]),\n",
    "            (\"colsample_bytree\", [  0.3, 0.4, 0.5, 0.7 ] ),\n",
    "            ])\n",
    "#n_trials=10000\n",
    "n_trials=100\n",
    "#method=genetic\n",
    "method=grid_search\n",
    "\n",
    "dfs = []\n",
    "for i in range(n_trials) :\n",
    "        if i % 100 == 0 :\n",
    "            print( \"trial = %d\" % i )\n",
    "        fun_eval = method( param_grid_dic, fun, seed=i )\n",
    "        df = pd.DataFrame( fun_eval.eval_log() ) \n",
    "        del df[\"pars\"]\n",
    "        df[\"method\"] = method.__name__\n",
    "        df[\"trial\"] = i\n",
    "        dfs.append( df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946fddf4-9768-45e6-9b90-78965cbec5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c6f6473-e4be-45fc-a8fd-c31777277c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./xgboost_memo%g'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memoization_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "240a73a3-7c68-4b29-baad-f2853f7d9330",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12352/2484865338.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdfs\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_hdf\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m\"df_gen_10.hdf\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"a/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \"\"\"\n\u001b[1;32m--> 294\u001b[1;33m     op = _Concatenator(\n\u001b[0m\u001b[0;32m    295\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No objects to concatenate\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "pd.concat( dfs ).to_hdf( \"df_gen_10.hdf\", \"a/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e69374-b4e7-4264-a612-685014fa2bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame( fun_eval.eval_log() ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "986f6155-ed5c-4cc7-8414-503a791815a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5d41402abc4b2a76b9719d911017c592'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashlib.md5( 'hello'.encode(\"utf8\") ).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78ebcd21-86b2-49e1-8674-ac541eb4a2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d590df-f529-4073-b561-ffe7ff3345c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b68c013-e842-4fbe-ac0d-aa816b589c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = Memoizer( lambda param_dic : train_xgb( data, param_dic ),\n",
    "                memoization_path )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aec4918-9089-4095-af53-5521771860df",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r\".\"\n",
    "\n",
    "param_grid_dic = OrderedDict([\n",
    "        (\"learning_rate\", [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ),\n",
    "        (\"max_depth\"    , [  3 , 4 , 5, 6,  8, 10, 12, 15 ] ),\n",
    "        (\"min_child_weight\", [ 1, 3, 5, 7 ] ),\n",
    "        (\"gamma\", [0.0, 0.1, 0.2, 0.3, 0.4 ]),\n",
    "        (\"colsample_bytree\", [  0.3, 0.4, 0.5, 0.7 ] ),\n",
    "        ])\n",
    "\n",
    "#%%\n",
    "train_fraction = 0.05\n",
    "test_fraction  = 0.16\n",
    "#data = subsample( data0, train_fraction, test_fraction )\n",
    "data=None\n",
    "#%%\n",
    "seed=1359\n",
    "log_level=0\n",
    "#%%\n",
    "memoization_path = DATA_DIR + \"/\" + \"xgboost_memo%g\" % train_fraction\n",
    "print( \"memoization_path= \" + memoization_path)\n",
    "if not os.path.exists( memoization_path ) :\n",
    "    os.mkdir( memoization_path )\n",
    "#%%\n",
    "fun = Memoizer( lambda param_dic : train_xgb( data, param_dic ),\n",
    "                memoization_path )\n",
    "#%%\n",
    "grid_search( param_grid_dic, fun )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e1ef428-0781-4f49-a620-f8d78a6afc05",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'md5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12352/429837625.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mparam_grid_dic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m42\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12352/2061167765.py\u001b[0m in \u001b[0;36mgrid_search\u001b[1;34m(param_grid_dic, fun, seed, log_level)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_dic\u001b[0m  \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mparam_combos_shuffled\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_eval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_fun\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mparam_dic\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlog_level\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mparam_dic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m  \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\Re-education\\Optimization\\hpar_opt_experiments\\inst_func_eval.py\u001b[0m in \u001b[0;36meval_fun\u001b[1;34m(self, param_dic, extra)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_dic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mfun_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fun\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mparam_dic\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_level\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m  \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\Re-education\\Optimization\\hpar_opt_experiments\\memoize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, param_dic)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mparam_dic\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mhex_hash\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmd5\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_dic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhex_hash\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'md5' is not defined"
     ]
    }
   ],
   "source": [
    "grid_search( param_grid_dic, fun, 42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cefcf6c-12ac-454d-b0d6-61ede286bef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61bd99a-8dae-412d-bee0-626c21d19819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc7f153-86a1-4bee-8f8a-def06a2b3b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f036afbe-544c-4423-b895-1523cc25c698",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'md5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12352/1741403226.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfun_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mife\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInstFunEvaluator\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid_dic\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhashlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmd5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfun_eval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_grid_dic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#    for i, param_dic  in enumerate( param_combos_shuffled ) :\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\Re-education\\Optimization\\hpar_opt_experiments\\inst_func_eval.py\u001b[0m in \u001b[0;36meval_fun\u001b[1;34m(self, param_dic, extra)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_dic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmd5\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m'hello'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mfun_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fun\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mparam_dic\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\Re-education\\Optimization\\hpar_opt_experiments\\memoize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, param_dic)\u001b[0m\n\u001b[0;32m     39\u001b[0m                   % self._refresh_every )\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mparam_dic\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         '''print(md5( 'hello'.encode(\"utf8\") ).hexdigest())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'md5' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d56b0d-a4c7-4d3c-bb38-31010d0438de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
