{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5846da79-9d1a-42ef-a904-11a36b8b7087",
   "metadata": {},
   "source": [
    "## Modeling for performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d03dd50-ea4f-49d1-8a0e-b4b847f39714",
   "metadata": {},
   "source": [
    "### implementing some learnings from Amazon Access (project 11)\n",
    "- generating multiple datasets \n",
    "- zipping datasets with models \n",
    "- stacking models for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e9ba757-efd3-47e2-a50b-e2ee6f2322eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn import metrics, linear_model, ensemble\n",
    "from yellowbrick.regressor import residuals_plot, prediction_error\n",
    "from fast_ml.model_development import train_valid_test_split\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from tpot import TPOTRegressor\n",
    "import category_encoders as ce\n",
    "import time\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "encoders = {\n",
    "\n",
    "    'BackwardDifferenceEncoder': ce.backward_difference.BackwardDifferenceEncoder,\n",
    "    'OneHotEncoder': ce.one_hot.OneHotEncoder,\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dbb945a-a221-46d2-98c0-3ee2343861b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('..')\n",
    "from Utils.Metrics import regression as reg_metrics\n",
    "os.chdir('./9. Clickstream data for online shopping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f630143b-9aff-47ee-aab1-fc1a78fe4b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_data_df = pd.read_csv('./data/e-shop data and description/e-shop clothing 2008.csv',sep=',').drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "be9fbfbf-cd62-4de3-b486-ba42e02bce94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "35d01c53-f86f-474c-b621-c54be684c52d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFJCAYAAACyzKU+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXSUlEQVR4nO3df0xV9/3H8de59wLWC4zwR5MvcRqwmpWwzgDBNrnS/tGUbkvXdbFFXewWnWud4mi0QamArlRlRpZZ02m3LEuwpp0/1u/+WTLn2jCgormJ60Bb08XaVmxTi6bcOwuXe8/3D7+yUSv30oGHN/f5+Kue+5H7ed+T8eRcuWeO67quAACAGT6vNwAAAMaHeAMAYAzxBgDAGOINAIAxxBsAAGMCXm8gFYlEQtFoVBkZGXIcx+vtAAAwqVzXVSwWUzAYlM9343W2iXhHo1GdPXvW620AAHBLzZ8/Xzk5OTccNxHvjIwMSdeGyMzM9GwfPT09Kikp8ez5vZTOs0vpPT+zp+fsUnrP7/XsQ0NDOnv27Ej/Ps9EvK+/VZ6ZmamsrCxP9+L183spnWeX0nt+Zk9f6Tz/VJj9Zv9UzC+sAQBgDPEGAMAY4g0AgDHEGwAAY4g3AADGEG8AAIwh3gAAGEO8AQAwhngDAGAM8QYAwBjiDQCAMSbubQ58Wf71bRP3xQ6cnriv9f/iu5ZP+NcEMP1x5Q0AgDHEGwAAY4g3AADGEG8AAIwh3gAAGEO8AQAwhngDAGAM8QYAwBjiDQCAMcQbAABjiDcAAMYQbwAAjCHeAAAYQ7wBADCGeAMAYAzxBgDAGOINAIAxxBsAAGOINwAAxhBvAACMId4AABhDvAEAMIZ4AwBgDPEGAMAY4g0AgDHEGwAAY4g3AADGEG8AAIwh3gAAGBNIZdEjjzyi7OxsSdKsWbNUXV2t5557Tn6/X6FQSGvXrlUikdCWLVv09ttvKzMzU83NzZozZ45OnTqV8loAAJBc0ngPDg7KdV21tbWNHHv44Yf1/PPP66tf/ap+/OMf6/Tp0/rggw80NDSkV155RadOndKOHTv0q1/9Sk1NTSmvBQAAySWN91tvvaWrV69qxYoVGh4eVk1NjYaGhjR79mxJUigUUldXlz7++GMtWrRIkrRgwQL19PQoEomkvBYAAKQmabxnzJihlStX6tFHH9W7776rVatWKTc3d+TxYDCo999/X5FIZOStdUny+/03HBtr7fDwsAKBsbczFSIfDoe93oJn0nn2yWLlNbWyz8mQzrNL6T3/VJ49abwLCws1Z84cOY6jwsJC5eTk6MqVKyOPR6NR5ebm6rPPPlM0Gh05nkgklJ2dPerYWGuThVuSSkpKlJWVlepsEy4cDqusrMyz5/eS2dkPnPZ6B2Oy8JqaPfcTIJ1nl9J7fq9nHxwcHPOCNelvmx86dEg7duyQJH300Ue6evWqZs6cqffee0+u66qjo0Pl5eUqLS1Ve3u7JOnUqVOaP3++srOzlZGRkdJaAACQmqSXu4sXL9amTZu0dOlSOY6jbdu2yefzacOGDYrH4wqFQvrGN76hr3/96+rs7NSSJUvkuq62bdsmSdq6dWvKawEAQHJJ452Zmaldu3bdcPz3v//9qD/7fD797Gc/u2HdggULUl4LAACS4yYtAAAYQ7wBADCGeAMAYAzxBgDAGOINAIAxxBsAAGOINwAAxhBvAACMId4AABhDvAEAMIZ4AwBgDPEGAMAY4g0AgDHEGwAAY4g3AADGEG8AAIwh3gAAGEO8AQAwhngDAGAM8QYAwBjiDQCAMcQbAABjiDcAAMYQbwAAjCHeAAAYQ7wBADCGeAMAYAzxBgDAGOINAIAxxBsAAGOINwAAxhBvAACMId4AABhDvAEAMIZ4AwBgDPEGAMAY4g0AgDHEGwAAY4g3AADGEG8AAIwh3gAAGEO8AQAwhngDAGBMSvH+5JNPdO+99+qf//ynzp8/r6VLl2rZsmVqampSIpGQJO3Zs0eLFy/WkiVL9Oabb0rSuNYCAIDUJI13LBZTY2OjZsyYIUnavn27amtrdeDAAbmuq2PHjqm3t1cnTpzQwYMH1draqq1bt457LQAASE3SeLe0tGjJkiW6/fbbJUm9vb2qqKiQJFVWVqqrq0vhcFihUEiO46igoEDxeFz9/f3jWgsAAFITGOvBI0eOKD8/X4sWLdKLL74oSXJdV47jSJKCwaAGBgYUiUSUl5c38veuHx/P2vz8/KSb7enpGe98Ey4cDnu9Bc+k8+yTxcpramWfkyGdZ5fSe/6pPPuY8T58+LAcx9Ebb7yhM2fOqK6ubtRVcjQaVW5urrKzsxWNRkcdz8nJkc/nS3ltKkpKSpSVlZXycBMtHA6rrKzMs+f3ktnZD5z2egdjsvCamj33EyCdZ5fSe36vZx8cHBzzgnXMt81feukl7d+/X21tbbrzzjvV0tKiyspKdXd3S5La29tVXl6u0tJSdXR0KJFIqK+vT4lEQvn5+SouLk55LQAASM2YV95fpK6uTg0NDWptbVVRUZGqqqrk9/tVXl6u6upqJRIJNTY2jnstAABITcrxbmtrG/nv/fv33/B4TU2NampqRh0rLCxMeS0AAEgNN2kBAMAY4g0AgDHEGwAAY4g3AADGEG8AAIwh3gAAGEO8AQAwhngDAGAM8QYAwBjiDQCAMcQbAABjiDcAAMYQbwAAjCHeAAAYQ7wBADCGeAMAYAzxBgDAGOINAIAxxBsAAGOINwAAxhBvAACMId4AABhDvAEAMIZ4AwBgDPEGAMAY4g0AgDHEGwAAY4g3AADGEG8AAIwh3gAAGEO8AQAwhngDAGAM8QYAwBjiDQCAMcQbAABjiDcAAMYQbwAAjCHeAAAYQ7wBADCGeAMAYAzxBgDAGOINAIAxgWQL4vG4Nm/erHPnzslxHG3dulVZWVnauHGjHMfRvHnz1NTUJJ/Ppz179uj1119XIBBQfX297rrrLp0/fz7ltQAAILmk8X7ttdckSS+//LK6u7v1i1/8Qq7rqra2VgsXLlRjY6OOHTumgoICnThxQgcPHtTFixdVU1Ojw4cPa/v27SmvBQAAySWN9/3336/77rtPktTX16fc3Fx1dXWpoqJCklRZWanOzk4VFhYqFArJcRwVFBQoHo+rv79fvb29Ka/Nz8+fvEkBAJgmksZbkgKBgOrq6nT06FHt3r1bnZ2dchxHkhQMBjUwMKBIJKK8vLyRv3P9uOu6Ka9NFu+enp5xjjfxwuGw11vwTDrPPlmsvKZW9jkZ0nl2Kb3nn8qzpxRvSWppadGGDRv02GOPaXBwcOR4NBpVbm6usrOzFY1GRx3PycmRz+dLeW0yJSUlysrKSnXLEy4cDqusrMyz5/eS2dkPnPZ6B2Oy8JqaPfcTIJ1nl9J7fq9nHxwcHPOCNelvm7/66qvat2+fJOm2226T4zgqKSlRd3e3JKm9vV3l5eUqLS1VR0eHEomE+vr6lEgklJ+fr+Li4pTXAgCA5JJeeT/wwAPatGmTvv/972t4eFj19fWaO3euGhoa1NraqqKiIlVVVcnv96u8vFzV1dVKJBJqbGyUJNXV1aW8FgAAJJc03jNnztQvf/nLG47v37//hmM1NTWqqakZdaywsDDltQAAIDlu0gIAgDHEGwAAY4g3AADGEG8AAIwh3gAAGJPyTVoAYKryr2+bvC8+ATf6ie9aPgEbAf6NK28AAIwh3gAAGEO8AQAwhngDAGAM8QYAwBjiDQCAMcQbAABjiDcAAMYQbwAAjCHeAAAYQ7wBADCGeAMAYAzxBgDAGOINAIAxxBsAAGOINwAAxhBvAACMId4AABhDvAEAMIZ4AwBgDPEGAMAY4g0AgDHEGwAAY4g3AADGEG8AAIwh3gAAGEO8AQAwhngDAGAM8QYAwBjiDQCAMcQbAABjiDcAAMYQbwAAjCHeAAAYQ7wBADCGeAMAYExgrAdjsZjq6+t14cIFDQ0NafXq1brjjju0ceNGOY6jefPmqampST6fT3v27NHrr7+uQCCg+vp63XXXXTp//nzKawEAQGrGjPcf//hH5eXlaefOnbpy5Yq++93v6mtf+5pqa2u1cOFCNTY26tixYyooKNCJEyd08OBBXbx4UTU1NTp8+LC2b9+e8loAAJCaMeP94IMPqqqqSpLkuq78fr96e3tVUVEhSaqsrFRnZ6cKCwsVCoXkOI4KCgoUj8fV398/rrX5+fmTPCoAANPDmPEOBoOSpEgkonXr1qm2tlYtLS1yHGfk8YGBAUUiEeXl5Y36ewMDA3JdN+W1qcS7p6dnvPNNuHA47PUWPJPOs08WK6+plX1OVZZfP8t7/29N5dnHjLckXbx4UWvWrNGyZcv00EMPaefOnSOPRaNR5ebmKjs7W9FodNTxnJwc+Xy+lNemoqSkRFlZWSmtnQzhcFhlZWWePb+XzM5+4LTXOxiThdfUxLnnPE8KE+d+kng9++Dg4JgXrGP+tvmlS5e0YsUKPf3001q8eLEkqbi4WN3d3ZKk9vZ2lZeXq7S0VB0dHUokEurr61MikVB+fv641gIAgNSMeeW9d+9effrpp3rhhRf0wgsvSJKeeeYZNTc3q7W1VUVFRaqqqpLf71d5ebmqq6uVSCTU2NgoSaqrq1NDQ0NKawEAQGrGjPfmzZu1efPmG47v37//hmM1NTWqqakZdaywsDDltQAAIDVJ/80b3vGvb/N6C6N97t8V47uWe7QRAEhv3GENAABjuPLGlzbl3hkAgDTBlTcAAMYQbwAAjCHeAAAYw795Ax6y8HsDJ5YVe70FAJ/DlTcAAMYQbwAAjCHeAAAYQ7wBADCGeAMAYAzxBgDAGOINAIAxxBsAAGOINwAAxhBvAACMId4AABhDvAEAMIZ4AwBgDPEGAMAY4g0AgDHEGwAAY4g3AADGEG8AAIwh3gAAGEO8AQAwhngDAGAM8QYAwBjiDQCAMcQbAABjiDcAAMYQbwAAjCHeAAAYQ7wBADCGeAMAYAzxBgDAGOINAIAxxBsAAGMCXm8AwNRWceC0dOC019sA8B+48gYAwBjiDQCAMSnF++9//7uWL18uSTp//ryWLl2qZcuWqampSYlEQpK0Z88eLV68WEuWLNGbb7457rUAACA1SeP961//Wps3b9bg4KAkafv27aqtrdWBAwfkuq6OHTum3t5enThxQgcPHlRra6u2bt067rUAACA1SeM9e/ZsPf/88yN/7u3tVUVFhSSpsrJSXV1dCofDCoVCchxHBQUFisfj6u/vH9daAACQmqTxrqqqUiDw719Kd11XjuNIkoLBoAYGBhSJRJSdnT2y5vrx8awFAACpGfdHxXy+f/c+Go0qNzdX2dnZikajo47n5OSMa20qenp6xrvdCRcOh73eAgBjLH/fsLz3/9ZUnn3c8S4uLlZ3d7cWLlyo9vZ23X333Zo9e7Z27typlStX6sMPP1QikVB+fv641qaipKREWVlZ4x5yooTDYZWVld26J+SztcC0cEu/b0ygW/49bwrxevbBwcExL1jHHe+6ujo1NDSotbVVRUVFqqqqkt/vV3l5uaqrq5VIJNTY2DjutQAAIDWO67qu15tI5vpPIOl25e1f33bLngvA5InvWu71Fr4Ur68+veT17Mm6x01aAAAwhngDAGAM8QYAwBjiDQCAMcQbAABjiDcAAMYQbwAAjCHeAAAYQ7wBADCGeAMAYAzxBgDAGOINAIAxxBsAAGOINwAAxhBvAACMId4AABhDvAEAMCbg9Qa84l/f9uX+4oHTE7sRAADGiStvAACMId4AABhDvAEAMIZ4AwBgDPEGAMAY4g0AgDHEGwAAY9L2c94AcKt86ftK3ELxXcu93gLGgStvAACMId4AABhDvAEAMIZ4AwBgDPEGAMAY4g0AgDHEGwAAY4g3AADGEG8AAIzhDmsAgCnPk7vUHTg9ruW38i51xBsAcPM4jjNguDV42xwAAGOINwAAxhBvAACMId4AABhDvAEAMIZ4AwBgjGcfFUskEtqyZYvefvttZWZmqrm5WXPmzPFqOwAAmOHZlfdf/vIXDQ0N6ZVXXtH69eu1Y8cOr7YCAIApnl15h8NhLVq0SJK0YMEC9fT03HSt67qSpKGhoQl7/v8JZkzY1wIAYHBwcMK+1vXeXe/f53kW70gkouzs7JE/+/1+DQ8PKxC4cUuxWEySdPbs2Ql7/v99eN6EfS0AAMa6CP2yYrGYZsyYccNxz+KdnZ2taDQ68udEIvGF4ZakYDCo+fPnKyMjQ47j3KotAgDgCdd1FYvFFAwGv/Bxz+JdWlqq1157Td/61rd06tQpzZ8//6ZrfT6fcnJybuHuAADw1hddcV/nuDd7Q32SXf9t87Nnz8p1XW3btk1z5871YisAAJjiWbwBAMCXw01aAAAwhngDAGCMZ7+wNtXFYjHV19frwoULGhoa0urVq3XHHXdo48aNchxH8+bNU1NTk3y+6ffzTzwe1+bNm3Xu3Dk5jqOtW7cqKysrLWa/7pNPPtH3vvc9/fa3v1UgEEir2R955JGRj3HOmjVL1dXVeu655+T3+xUKhbR27VqPdzh59u3bp7/+9a+KxWJaunSpKioq0ubcHzlyRH/4wx8kXfu88pkzZ9TW1pYW5z4Wi2njxo26cOGCfD6fnn322an/v3sXX+jQoUNuc3Oz67que/nyZffee+91n3jiCff48eOu67puQ0OD++c//9nLLU6ao0ePuhs3bnRd13WPHz/uPvnkk2kzu+u67tDQkPuTn/zEfeCBB9x33nknrWb/7LPP3IcffnjUse985zvu+fPn3UQi4f7oRz9ye3t7vdncJDt+/Lj7xBNPuPF43I1EIu7u3bvT6tz/py1btrgvv/xy2pz7o0ePuuvWrXNd13U7OjrctWvXTvlzP4V+jJhaHnzwQf30pz+VdO3zdn6/X729vaqoqJAkVVZWqqury8stTpr7779fzz77rCSpr69Pubm5aTO7JLW0tGjJkiW6/fbbJSmtZn/rrbd09epVrVixQo8//rhOnjypoaEhzZ49W47jKBQKTdv5Ozo6NH/+fK1Zs0ZPPvmk7rvvvrQ699f94x//0DvvvKNvf/vbaXPuCwsLFY/HlUgkFIlEFAgEpvy5523zm7j+wfhIJKJ169aptrZWLS0tIzeJCQaDGhgY8HKLkyoQCKiurk5Hjx7V7t271dnZmRazHzlyRPn5+Vq0aJFefPFFSdd+eEuH2aVrnytduXKlHn30Ub377rtatWqVcnNzRx4PBoN6//33Pdzh5Ll8+bL6+vq0d+9effDBB1q9enVanfvr9u3bpzVr1txwF8zpfO5nzpypCxcu6Jvf/KYuX76svXv36uTJk1P63BPvMVy8eFFr1qzRsmXL9NBDD2nnzp0jj0Wj0VHf1KajlpYWbdiwQY899tioe/ZO59kPHz4sx3H0xhtv6MyZM6qrq1N/f//I49N5dunaFcicOXPkOI4KCwuVk5OjK1eujDw+nefPy8tTUVGRMjMzVVRUpKysLH344Ycjj0/n2a/79NNPde7cOd19992KRCKj7oI5nef/3e9+p1AopPXr1+vixYv6wQ9+MHJbbmlqzs7b5jdx6dIlrVixQk8//bQWL14sSSouLlZ3d7ckqb29XeXl5V5ucdK8+uqr2rdvnyTptttuk+M4KikpSYvZX3rpJe3fv19tbW2688471dLSosrKyrSYXZIOHTo08v/w99FHH+nq1auaOXOm3nvvPbmuq46Ojmk7f1lZmf72t7/Jdd2R2e+55560OfeSdPLkSd1zzz2Srt3COiMjIy3OfW5u7shdPL/yla9oeHh4yn+/5yYtN9Hc3Kw//elPKioqGjn2zDPPqLm5WbFYTEVFRWpubpbf7/dwl5PjX//6lzZt2qRLly5peHhYq1at0ty5c9XQ0DDtZ/9Py5cv15YtW+Tz+dJm9qGhIW3atEl9fX1yHEcbNmyQz+fTtm3bFI/HFQqF9NRTT3m9zUnz85//XN3d3XJdV0899ZRmzZqVNudekn7zm98oEAjohz/8oSTp1KlTaXHuo9Go6uvr9fHHHysWi+nxxx9XSUnJlD73xBsAAGN42xwAAGOINwAAxhBvAACMId4AABhDvAEAMIZ4AwBgDPEGAMAY4g0AgDH/BwYY330Nio8fAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d08b2e09-e858-46c2-960b-499ac035327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_models = [\n",
    "    \"LR:dataset1\",\n",
    "    \"LR:dataset2\",\n",
    "    \"LR:dataset3\",\n",
    "    \"LR:dataset4\",\n",
    "    \"RFC:dataset1\",\n",
    "    \"RFC:dataset2\",\n",
    "    \"RFC:dataset3\",\n",
    "    \"RFC:dataset4\",\n",
    "    \"GBC:dataset1\",\n",
    "    \"GBC:dataset2\",\n",
    "    \"GBC:dataset3\",\n",
    "    \"GBC:dataset4\"\n",
    "]\n",
    "\n",
    "models = []\n",
    "for item in selected_models:\n",
    "    model_id, dataset = item.split(':')\n",
    "    # instantiating models (with datasets)\n",
    "    model = {'LR': linear_model.LogisticRegression,\n",
    "             'GBC': ensemble.GradientBoostingClassifier,\n",
    "             'RFC': ensemble.RandomForestClassifier,\n",
    "             'ETC': ensemble.ExtraTreesClassifier}[model_id]() \n",
    "    model.set_params()\n",
    "    models.append((model, dataset))\n",
    "\n",
    "datasets = [dataset for model, dataset in models]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b225a5-a5c9-4b83-a594-1057bbdbafd6",
   "metadata": {},
   "source": [
    "## Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cdf397-623a-46ba-92bd-fe015af84246",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clothing_data_df.drop('price', axis=1)\n",
    "y = clothing_data_df['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6bed3eb4-0ee2-46e6-a461-5ee76e71af19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 1\n",
    "# Create a dataset where the features are the effects of a logistic regression trained on sparsified data.\n",
    "# Essentially what this would give you is the exact effect of the value of a feature on the target. would work if target is binary but in my case there are twenty unique values\n",
    "# redefine target to <= 40 or > 40\n",
    "y = (y <= 40).astype(int)\n",
    "\n",
    "def sparsify(X, X_test):\n",
    "    \"\"\"Return One-Hot encoded datasets.\"\"\"\n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(np.vstack((X, X_test)))\n",
    "    return enc.transform(X.values), enc.transform(X_test.values)\n",
    "\n",
    "from sklearn import linear_model \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "Xe_train = np.zeros(X_train.shape)\n",
    "Xe_test = np.zeros(X_test.shape)\n",
    "n_cols = Xe_train.shape[1]\n",
    "\n",
    "model = linear_model.LogisticRegression(C=2)\n",
    "X_train, X_test = sparsify(X_train, X_test)\n",
    "\n",
    "kfold = KFold(5)\n",
    "\n",
    "# alrighty. so what's happening is unrolling of all unique values in all columns, for each of these columns, training a logistic model and then slotting those values (coeffs) back into the unrolled spaces\n",
    "for train, cv in kfold.split(X_train):\n",
    "    model.fit(X_train[train], y[train])\n",
    "    colindices = X_test.nonzero()[1] #flattened non zero col indices #remember the data has been sparsified so 14501 unique col indices and 364045 non unique\n",
    "    for i, k in zip(cv, range(len(cv))): # i - row number, k - row index\n",
    "        for j in range(n_cols): #n_cols is 11 (pre sparsify)\n",
    "            z = colindices[n_cols*k + j]\n",
    "            Xe_train[i, j] = model.coef_[0, z]\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "colindices = X_test.nonzero()[1]\n",
    "for i in range(Xe_test.shape[0]):\n",
    "    for j in range(n_cols):\n",
    "        z = colindices[n_cols*i + j]\n",
    "        Xe_test[i, j] = model.coef_[0, z]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8353a7c-ab31-419c-b402-89910cf3bce7",
   "metadata": {},
   "source": [
    "## Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b4b0a703-2143-44ec-ae80-0faaada40318",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clothing_data_df.drop('price', axis=1)\n",
    "y = clothing_data_df['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c786f069-0ec8-47a9-b12a-854ab07c4a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with polynomial features \n",
    "    \n",
    "# ordinal encode \n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(np.hstack((X_train['page 2 (clothing model)'], X_test['page 2 (clothing model)'])))\n",
    "X_train['page 2 (clothing model)'] = le.transform(X_train['page 2 (clothing model)'])\n",
    "X_test['page 2 (clothing model)'] = le.transform(X_test['page 2 (clothing model)'])\n",
    "    \n",
    "X_train = list(X_train.T.values)\n",
    "X_test = list(X_test.T.values)\n",
    "X_train = [list(feature) for feature in X_train]\n",
    "X_test = [list(feature) for feature in X_test]\n",
    "\n",
    "n_features = len(X_train)    \n",
    "    \n",
    "for i in range(n_features):\n",
    "    #for j in range(1): j = 0 ? ratio of all features with first one? is it maybe meant to be range(i+1,n_features)? \n",
    "    for j in range(i+1,n_features):\n",
    "        X_train.append([round(a/(b + 1), 3) for a, b in zip(X_train[i], X_train[j])])\n",
    "        X_test.append([round(a/(b + 1), 3) for a, b in zip(X_test[i], X_test[j])])\n",
    "\n",
    "        X_train.append([round(a/(b + 1), 3) for a, b in zip(X_train[j], X_train[i])])\n",
    "        X_test.append([round(a/(b + 1), 3) for a, b in zip(X_test[j], X_test[i])])\n",
    "\n",
    "        X_train.append([a*b for a, b in zip(X_train[j], X_train[i])])\n",
    "        X_test.append([a*b for a, b in zip(X_test[j], X_test[i])])\n",
    "\n",
    "# remove constant features\n",
    "for i in range(len(X_train) - 1, -1, -1):\n",
    "    if np.var(X_train[i]) + np.var(X_test[i]) == 0:\n",
    "        X_train.pop(i)\n",
    "        X_test.pop(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9773f007-e621-43f1-992d-f4cf4a678bc6",
   "metadata": {},
   "source": [
    "## Dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc218a9-18b6-4e2c-87d9-b61196ce66d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clothing_data_df.drop('price', axis=1)\n",
    "y = clothing_data_df['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(np.hstack((X_train['page 2 (clothing model)'], X_test['page 2 (clothing model)'])))\n",
    "X_train['page 2 (clothing model)'] = le.transform(X_train['page 2 (clothing model)'])\n",
    "X_test['page 2 (clothing model)'] = le.transform(X_test['page 2 (clothing model)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9945a6cb-1cae-485a-856a-fdbf55b99756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import linear_model \n",
    "from sklearn.model_selection import cross_validate as cross_validation\n",
    "from scipy import sparse\n",
    "from itertools import combinations\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a865cf3a-886e-4744-8094-ea559ca3ab51",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 217 Mean AUC: 0.993969\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24244/901295238.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mfeats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgood_features\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mXts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeats\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m             \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m\"Feature: %i Mean AUC: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24244/901295238.py\u001b[0m in \u001b[0;36mcv_loop\u001b[1;34m(X, y, model, N, print_score)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#[:, 1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ovr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1587\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1588\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"processes\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1589\u001b[1;33m         fold_coefs_ = Parallel(\n\u001b[0m\u001b[0;32m   1590\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1591\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    804\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m             ]\n\u001b[1;32m--> 806\u001b[1;33m             opt_res = optimize.minimize(\n\u001b[0m\u001b[0;32m    807\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[0mw0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    621\u001b[0m                                   **options)\n\u001b[0;32m    622\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[0;32m    624\u001b[0m                                 callback=callback, **options)\n\u001b[0;32m    625\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfunc\u001b[1;34m(x, *args)\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 774\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_multinomial_loss_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"newton-cg\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss_grad\u001b[1;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[0;32m    346\u001b[0m     \u001b[0mfit_intercept\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_features\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_multinomial_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m     \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss\u001b[1;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mintercept\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msquared_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AutoML\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     45\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[0;32m     46\u001b[0m          initial=_NoValue, where=True):\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# using Amazon Access greedy feature creation\n",
    "\n",
    "def group_data(data, degree=3, hash=hash):\n",
    "    new_data = []\n",
    "    m, n = data.shape\n",
    "    for indices in combinations(range(n), degree):\n",
    "        new_data.append([hash(tuple(v)) for v in data.values[:, indices]])\n",
    "    return np.array(new_data).T\n",
    "\n",
    "def OneHotEncoder(data, keymap=None):\n",
    "    \"\"\"\n",
    "    OneHotEncoder takes data matrix with categorical columns and\n",
    "    converts it to a sparse binary matrix.\n",
    "\n",
    "    Returns sparse binary matrix and keymap mapping categories to indicies.\n",
    "    \"\"\"\n",
    "    if keymap is None:\n",
    "        keymap = []\n",
    "        for col in data.T:\n",
    "            uniques = set(list(col))\n",
    "            keymap.append(dict((key, i) for i, key in enumerate(uniques)))\n",
    "    total_pts = data.shape[0]\n",
    "    outdat = []\n",
    "    for i, col in enumerate(data.T):\n",
    "        km = keymap[i]\n",
    "        num_labels = len(km)\n",
    "        spmat = sparse.lil_matrix((total_pts, num_labels))\n",
    "        for j, val in enumerate(col):\n",
    "            if val in km:\n",
    "                spmat[j, km[val]] = 1\n",
    "        outdat.append(spmat)\n",
    "    outdat = sparse.hstack(outdat).tocsr()\n",
    "    return outdat\n",
    "    \n",
    "def cv_loop(X, y, model, N, print_score=False):\n",
    "    mean_auc = 0.\n",
    "    for i in range(N):\n",
    "        X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=.20)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict_proba(X_cv)#[:, 1]\n",
    "        auc = metrics.roc_auc_score(y_cv, preds, multi_class='ovr')\n",
    "        if print_score:\n",
    "            print (\"AUC (fold %d/%d): %f\" % (i + 1, N, auc))\n",
    "        mean_auc += auc\n",
    "    return mean_auc/N    \n",
    "    \n",
    "num_train = X_train.shape[0]\n",
    "\n",
    "# Transform data\n",
    "dp = group_data(X, degree=2)\n",
    "dt = group_data(X, degree=3)\n",
    "\n",
    "\n",
    "X_2 = dp[:num_train]\n",
    "X_3 = dt[:num_train]\n",
    "\n",
    "X_test = X[num_train:]\n",
    "X = X_train\n",
    "\n",
    "X_test_2 = dp[num_train:]\n",
    "X_test_3 = dt[num_train:]\n",
    "\n",
    "X_train_all = np.hstack((X, X_2, X_3))\n",
    "X_test_all = np.hstack((X_test, X_test_2, X_test_3))\n",
    "num_features = X_train_all.shape[1]\n",
    "\n",
    "model = linear_model.LogisticRegression()\n",
    "\n",
    "# Xts holds one hot encodings for each individual feature in memory\n",
    "# speeding up feature selection\n",
    "Xts = [OneHotEncoder(X_train_all[:, [i]]) for i in range(num_features)]\n",
    "\n",
    "## greedy feature selection\n",
    "score_hist = []\n",
    "N = 10\n",
    "# Greedy feature selection loop\n",
    "good_features = set([124,193,217,6])\n",
    "while len(score_hist) < 2 or score_hist[-1][0] > score_hist[-2][0]: #keep in loop if less than two features, stop criteria is when mean auc score starts to drop\n",
    "    scores = []\n",
    "    for f in np.random.choice(range(len(Xts)), size=6, replace=False): #added sampling to randomize and speed up results. from past runs it seems like there is a high number of high-scoring features and each run takes long. 6 is enough.\n",
    "        if f not in good_features:\n",
    "            feats = list(good_features) + [f]\n",
    "            Xt = sparse.hstack([Xts[j] for j in feats]).tocsr()\n",
    "            score = cv_loop(Xt, y_train, model, N)\n",
    "            scores.append((score, f))\n",
    "            print( \"Feature: %i Mean AUC: %f\" % (f, score))\n",
    "    good_features.add(sorted(scores)[-2][1]) #unlikely that there will be a mean auc of 1 but if there is, choose the second largest. \n",
    "    score_hist.append(sorted(scores)[-2])\n",
    "    print (\"Current features: %s\" % sorted(list(good_features)))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b98cffed-eb95-4511-b224-47aeb2a20d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0 Mean AUC: 0.519881\n",
      "Feature: 1 Mean AUC: 0.506239\n",
      "Feature: 2 Mean AUC: 0.557360\n",
      "Feature: 3 Mean AUC: 0.532891\n",
      "Feature: 4 Mean AUC: 0.564970\n",
      "Feature: 5 Mean AUC: 0.818178\n",
      "Feature: 6 Mean AUC: 1.000000\n",
      "Feature: 7 Mean AUC: 0.856719\n",
      "Feature: 8 Mean AUC: 0.796027\n",
      "Feature: 9 Mean AUC: 0.630309\n",
      "Feature: 10 Mean AUC: 0.720923\n",
      "Feature: 11 Mean AUC: 0.520759\n",
      "Feature: 12 Mean AUC: 0.554918\n",
      "Feature: 13 Mean AUC: 0.547082\n",
      "Feature: 14 Mean AUC: 0.564948\n",
      "Feature: 15 Mean AUC: 0.824075\n",
      "Feature: 16 Mean AUC: 1.000000\n",
      "Feature: 17 Mean AUC: 0.859993\n",
      "Feature: 18 Mean AUC: 0.800280\n",
      "Feature: 19 Mean AUC: 0.644695\n",
      "Feature: 20 Mean AUC: 0.732835\n",
      "Feature: 21 Mean AUC: 0.533662\n",
      "Feature: 22 Mean AUC: 0.527660\n",
      "Feature: 23 Mean AUC: 0.565934\n",
      "Feature: 24 Mean AUC: 0.818604\n",
      "Feature: 25 Mean AUC: 0.999982\n",
      "Feature: 26 Mean AUC: 0.852646\n",
      "Feature: 27 Mean AUC: 0.793993\n",
      "Feature: 28 Mean AUC: 0.632552\n",
      "Feature: 29 Mean AUC: 0.720464\n",
      "Feature: 30 Mean AUC: 0.566662\n",
      "Feature: 31 Mean AUC: 0.500000\n",
      "Feature: 32 Mean AUC: 0.824614\n",
      "Feature: 33 Mean AUC: 0.998877\n",
      "Feature: 34 Mean AUC: 0.855008\n",
      "Feature: 35 Mean AUC: 0.802845\n",
      "Feature: 36 Mean AUC: 0.657147\n",
      "Feature: 37 Mean AUC: 0.732396\n",
      "Feature: 38 Mean AUC: 0.566751\n",
      "Feature: 39 Mean AUC: 0.821007\n",
      "Feature: 40 Mean AUC: 0.999918\n",
      "Feature: 41 Mean AUC: 0.860536\n",
      "Feature: 42 Mean AUC: 0.802000\n",
      "Feature: 43 Mean AUC: 0.646466\n",
      "Feature: 44 Mean AUC: 0.733853\n",
      "Feature: 45 Mean AUC: 0.619231\n",
      "Feature: 46 Mean AUC: 0.610546\n",
      "Feature: 47 Mean AUC: 0.567720\n",
      "Feature: 48 Mean AUC: 0.576224\n",
      "Feature: 49 Mean AUC: 0.567876\n",
      "Feature: 50 Mean AUC: 0.590954\n",
      "Feature: 51 Mean AUC: 1.000000\n",
      "Feature: 52 Mean AUC: 0.940729\n",
      "Feature: 53 Mean AUC: 0.929885\n",
      "Feature: 54 Mean AUC: 0.859217\n",
      "Feature: 55 Mean AUC: 0.890625\n",
      "Feature: 56 Mean AUC: 1.000000\n",
      "Feature: 57 Mean AUC: 1.000000\n",
      "Feature: 58 Mean AUC: 1.000000\n",
      "Feature: 59 Mean AUC: 1.000000\n",
      "Feature: 60 Mean AUC: 0.958730\n",
      "Feature: 61 Mean AUC: 0.897061\n",
      "Feature: 62 Mean AUC: 0.927559\n",
      "Feature: 63 Mean AUC: 0.850612\n",
      "Feature: 64 Mean AUC: 0.898664\n",
      "Feature: 65 Mean AUC: 0.782919\n",
      "Feature: 66 Mean AUC: 0.518005\n",
      "Feature: 67 Mean AUC: 0.535443\n",
      "Feature: 68 Mean AUC: 0.565658\n",
      "Feature: 69 Mean AUC: 0.808221\n",
      "Feature: 70 Mean AUC: 0.994596\n",
      "Feature: 71 Mean AUC: 0.820693\n",
      "Feature: 72 Mean AUC: 0.778211\n",
      "Feature: 73 Mean AUC: 0.630707\n",
      "Feature: 74 Mean AUC: 0.716169\n",
      "Feature: 75 Mean AUC: 0.560046\n",
      "Feature: 76 Mean AUC: 0.500000\n",
      "Feature: 77 Mean AUC: 0.811207\n",
      "Feature: 78 Mean AUC: 0.986091\n",
      "Feature: 79 Mean AUC: 0.829817\n",
      "Feature: 80 Mean AUC: 0.784758\n",
      "Feature: 81 Mean AUC: 0.646704\n",
      "Feature: 82 Mean AUC: 0.715576\n",
      "Feature: 83 Mean AUC: 0.565148\n",
      "Feature: 84 Mean AUC: 0.825238\n",
      "Feature: 85 Mean AUC: 0.999492\n",
      "Feature: 86 Mean AUC: 0.860473\n",
      "Feature: 87 Mean AUC: 0.803086\n",
      "Feature: 88 Mean AUC: 0.656355\n",
      "Feature: 89 Mean AUC: 0.739992\n",
      "Feature: 90 Mean AUC: 0.617976\n",
      "Feature: 91 Mean AUC: 0.611404\n",
      "Feature: 92 Mean AUC: 0.567127\n",
      "Feature: 93 Mean AUC: 0.576383\n",
      "Feature: 94 Mean AUC: 0.566342\n",
      "Feature: 95 Mean AUC: 0.588282\n",
      "Feature: 96 Mean AUC: 1.000000\n",
      "Feature: 97 Mean AUC: 0.942174\n",
      "Feature: 98 Mean AUC: 0.931228\n",
      "Feature: 99 Mean AUC: 0.863004\n",
      "Feature: 100 Mean AUC: 0.893024\n",
      "Feature: 101 Mean AUC: 1.000000\n",
      "Feature: 102 Mean AUC: 1.000000\n",
      "Feature: 103 Mean AUC: 1.000000\n",
      "Feature: 104 Mean AUC: 1.000000\n",
      "Feature: 105 Mean AUC: 0.959470\n",
      "Feature: 106 Mean AUC: 0.899536\n",
      "Feature: 107 Mean AUC: 0.928819\n",
      "Feature: 108 Mean AUC: 0.853881\n",
      "Feature: 109 Mean AUC: 0.900458\n",
      "Feature: 110 Mean AUC: 0.790553\n",
      "Feature: 111 Mean AUC: 0.534427\n",
      "Feature: 112 Mean AUC: 0.500000\n",
      "Feature: 113 Mean AUC: 0.760292\n",
      "Feature: 114 Mean AUC: 0.889594\n",
      "Feature: 115 Mean AUC: 0.739608\n",
      "Feature: 116 Mean AUC: 0.707777\n",
      "Feature: 117 Mean AUC: 0.593488\n",
      "Feature: 118 Mean AUC: 0.650809\n",
      "Feature: 119 Mean AUC: 0.566562\n",
      "Feature: 120 Mean AUC: 0.812895\n",
      "Feature: 121 Mean AUC: 0.995888\n",
      "Feature: 122 Mean AUC: 0.842102\n",
      "Feature: 123 Mean AUC: 0.788488\n",
      "Feature: 124 Mean AUC: 0.637936\n",
      "Feature: 125 Mean AUC: 0.725415\n",
      "Feature: 126 Mean AUC: 0.618071\n",
      "Feature: 127 Mean AUC: 0.611368\n",
      "Feature: 128 Mean AUC: 0.567151\n",
      "Feature: 129 Mean AUC: 0.580092\n",
      "Feature: 130 Mean AUC: 0.567623\n",
      "Feature: 131 Mean AUC: 0.591396\n",
      "Feature: 132 Mean AUC: 0.999985\n",
      "Feature: 133 Mean AUC: 0.937592\n",
      "Feature: 134 Mean AUC: 0.928384\n",
      "Feature: 135 Mean AUC: 0.858043\n",
      "Feature: 136 Mean AUC: 0.888840\n",
      "Feature: 137 Mean AUC: 0.999981\n",
      "Feature: 138 Mean AUC: 0.999986\n",
      "Feature: 139 Mean AUC: 0.999985\n",
      "Feature: 140 Mean AUC: 0.999984\n",
      "Feature: 141 Mean AUC: 0.956639\n",
      "Feature: 142 Mean AUC: 0.893098\n",
      "Feature: 143 Mean AUC: 0.924515\n",
      "Feature: 144 Mean AUC: 0.849179\n",
      "Feature: 145 Mean AUC: 0.893320\n",
      "Feature: 146 Mean AUC: 0.781626\n",
      "Feature: 147 Mean AUC: 0.500000\n",
      "Feature: 148 Mean AUC: 0.817917\n",
      "Feature: 149 Mean AUC: 0.990844\n",
      "Feature: 150 Mean AUC: 0.843673\n",
      "Feature: 151 Mean AUC: 0.795743\n",
      "Feature: 152 Mean AUC: 0.657003\n",
      "Feature: 153 Mean AUC: 0.728255\n",
      "Feature: 154 Mean AUC: 0.500000\n",
      "Feature: 155 Mean AUC: 0.500000\n",
      "Feature: 156 Mean AUC: 0.500000\n",
      "Feature: 157 Mean AUC: 0.500000\n",
      "Feature: 158 Mean AUC: 0.500000\n",
      "Feature: 159 Mean AUC: 0.500000\n",
      "Feature: 160 Mean AUC: 0.998644\n",
      "Feature: 161 Mean AUC: 0.935155\n",
      "Feature: 162 Mean AUC: 0.928545\n",
      "Feature: 163 Mean AUC: 0.861892\n",
      "Feature: 164 Mean AUC: 0.888959\n",
      "Feature: 165 Mean AUC: 0.998631\n",
      "Feature: 166 Mean AUC: 0.998711\n",
      "Feature: 167 Mean AUC: 0.998808\n",
      "Feature: 168 Mean AUC: 0.998702\n",
      "Feature: 169 Mean AUC: 0.954510\n",
      "Feature: 170 Mean AUC: 0.894223\n",
      "Feature: 171 Mean AUC: 0.921637\n",
      "Feature: 172 Mean AUC: 0.853098\n",
      "Feature: 173 Mean AUC: 0.892099\n",
      "Feature: 174 Mean AUC: 0.786612\n",
      "Feature: 175 Mean AUC: 0.619880\n",
      "Feature: 176 Mean AUC: 0.611146\n",
      "Feature: 177 Mean AUC: 0.566308\n",
      "Feature: 178 Mean AUC: 0.579281\n",
      "Feature: 179 Mean AUC: 0.566915\n",
      "Feature: 180 Mean AUC: 0.589387\n",
      "Feature: 181 Mean AUC: 0.999905\n",
      "Feature: 182 Mean AUC: 0.940134\n",
      "Feature: 183 Mean AUC: 0.929323\n",
      "Feature: 184 Mean AUC: 0.860044\n",
      "Feature: 185 Mean AUC: 0.890723\n",
      "Feature: 186 Mean AUC: 0.999915\n",
      "Feature: 187 Mean AUC: 0.999915\n",
      "Feature: 188 Mean AUC: 0.999919\n",
      "Feature: 189 Mean AUC: 0.999925\n",
      "Feature: 190 Mean AUC: 0.959247\n",
      "Feature: 191 Mean AUC: 0.899706\n",
      "Feature: 192 Mean AUC: 0.928489\n",
      "Feature: 193 Mean AUC: 0.854475\n",
      "Feature: 194 Mean AUC: 0.901199\n",
      "Feature: 195 Mean AUC: 0.790868\n",
      "Feature: 196 Mean AUC: 0.610176\n",
      "Feature: 197 Mean AUC: 0.584388\n",
      "Feature: 198 Mean AUC: 0.599469\n",
      "Feature: 199 Mean AUC: 0.611035\n",
      "Feature: 200 Mean AUC: 0.620126\n",
      "Feature: 201 Mean AUC: 0.611195\n",
      "Feature: 202 Mean AUC: 0.608699\n",
      "Feature: 203 Mean AUC: 0.610190\n",
      "Feature: 204 Mean AUC: 0.611673\n",
      "Feature: 205 Mean AUC: 0.586059\n",
      "Feature: 206 Mean AUC: 0.578737\n",
      "Feature: 207 Mean AUC: 0.571005\n",
      "Feature: 208 Mean AUC: 0.577632\n",
      "Feature: 209 Mean AUC: 0.596550\n",
      "Feature: 210 Mean AUC: 0.587992\n",
      "Feature: 211 Mean AUC: 1.000000\n",
      "Feature: 212 Mean AUC: 1.000000\n",
      "Feature: 213 Mean AUC: 1.000000\n",
      "Feature: 214 Mean AUC: 1.000000\n",
      "Feature: 215 Mean AUC: 0.989070\n",
      "Feature: 216 Mean AUC: 0.958158\n",
      "Feature: 217 Mean AUC: 0.969397\n",
      "Feature: 218 Mean AUC: 0.953367\n",
      "Feature: 219 Mean AUC: 0.975228\n",
      "Feature: 220 Mean AUC: 0.919320\n",
      "Feature: 221 Mean AUC: 1.000000\n",
      "Feature: 222 Mean AUC: 1.000000\n",
      "Feature: 223 Mean AUC: 1.000000\n",
      "Feature: 224 Mean AUC: 1.000000\n",
      "Feature: 225 Mean AUC: 1.000000\n",
      "Feature: 226 Mean AUC: 1.000000\n",
      "Feature: 227 Mean AUC: 0.975814\n",
      "Feature: 228 Mean AUC: 0.986694\n",
      "Feature: 229 Mean AUC: 0.952338\n",
      "Feature: 230 Mean AUC: 0.933205\n"
     ]
    }
   ],
   "source": [
    "# try selecting all features of mean AUC 1\n",
    "feature_mean_auc_scores = []\n",
    "for f in range(len(Xts)): \n",
    "    Xt = sparse.hstack([Xts[f]]).tocsr()\n",
    "    score = cv_loop(Xt, y_train, model, N)\n",
    "    feature_mean_auc_scores.append((score, f))\n",
    "    print( \"Feature: %i Mean AUC: %f\" % (f, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1d482fd-27fb-422a-9647-11e8ee89abb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_features = [x[1] for x in feature_mean_auc_scores if x[0] > 0.9]\n",
    "len(good_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b72958-ecae-4ad1-b46a-aed2d00d6f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove last added feature from good_features\n",
    "#good_features.remove(score_hist[-1][1])\n",
    "#good_features = sorted(list(good_features))\n",
    "\n",
    "for i, good_features in enumerate(good_features_list):\n",
    "    suffix = str(i + 1) if i else ''\n",
    "    Xt = np.vstack((X_train_all[:, good_features],\n",
    "                    X_test_all[:, good_features]))\n",
    "    X_train = Xt[:num_train]\n",
    "    X_test = Xt[num_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a6bf81-3bd5-40d6-96c9-7dc3c17ba171",
   "metadata": {},
   "source": [
    "# Dataset 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c95c1a2-40c9-4e12-a625-e067cb0dc49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clothing_data_df.drop('price', axis=1)\n",
    "y = clothing_data_df['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(np.hstack((X_train['page 2 (clothing model)'], X_test['page 2 (clothing model)'])))\n",
    "X_train['page 2 (clothing model)'] = le.transform(X_train['page 2 (clothing model)'])\n",
    "X_test['page 2 (clothing model)'] = le.transform(X_test['page 2 (clothing model)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83361635-dcbb-4778-bb2f-8cb0b13c3ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(data, degree=2, operation=None):\n",
    "    new_data = []\n",
    "    m, n = data.shape\n",
    "    for indices in combinations(range(n), degree):\n",
    "        if operation=='addition':\n",
    "            new_data.append([np.sum(tuple(v)) for v in data.values[:, indices]])\n",
    "        elif operation=='subtraction':\n",
    "            new_data.append([(v[0]-v[1]) for v in data.values[:, indices]])\n",
    "        elif operation=='multiplication':\n",
    "            new_data.append([(v[0]*v[1]) for v in data.values[:, indices]])\n",
    "        elif operation=='division':\n",
    "            new_data.append([(v[0]/v[1]) for v in data.values[:, indices]])\n",
    "    return np.array(new_data).T\n",
    "\n",
    "operations=['addition','subtraction','multiplication','division']\n",
    "golden_features=combine_features(X_train, operation=operations[0])\n",
    "for op in operations[1:]:\n",
    "    golden_features=np.hstack((golden_features,combine_features(X_train, operation=op)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771f103e-bccc-4034-97ff-8a45094d1ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72c3301f-8c9d-4b50-b937-dc76c700f6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, -1, -2, -3, -4]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237b1283-fdd5-4c60-ae6a-44771286ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 4: run Boruta feature selection algo for 'golden features' https://mljar.com/automated-machine-learning/golden-features/#:~:text=Golden%20Featues%20Generation%20Overview,power%20of%20newly%20created%20features.\n",
    "# reall great explanation https://towardsdatascience.com/boruta-explained-the-way-i-wish-someone-explained-it-to-me-4489d70e154a\n",
    "\n",
    "\n",
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest = RandomForestRegressor(\n",
    "   n_jobs = -1, \n",
    "   max_depth = 5\n",
    ")\n",
    "boruta = BorutaPy(\n",
    "   estimator = forest, \n",
    "   n_estimators = 'auto',\n",
    "   max_iter = 100 # number of trials to perform\n",
    ")\n",
    "\n",
    "boruta.fit(np.array(X), np.array(y))\n",
    "\n",
    "green_area = X.columns[boruta.support_].to_list()\n",
    "blue_area = X.columns[boruta.support_weak_].to_list()\n",
    "print('features in the green area:', green_area)\n",
    "print('features in the blue area:', blue_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f48477f3-0d62-47df-910a-d53de9e8de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 5: original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80346895-2740-441c-803d-3a00b717a751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772bbb82-d328-4f5f-9449-d84ec305066e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e3d307-db3c-4b8a-932b-1161e382e305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8178bcde-bcc3-4bbc-bbf9-cbf6e22c134e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b3b7f-e388-4813-ac73-aa4cde8da905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1454a346-a61a-43b4-b25d-872d7bc83305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e85b265-1d99-47bf-92c2-ea50a8b575ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6dae19-8c2e-4c1b-8b2c-2d511d66a461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd938a82-260d-4e74-88bf-8e2c6553adcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b88d8e-093f-42cd-b0e7-b7fdf1276c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfe2d37-f603-4f3d-86eb-e523973f0124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357dfc79-5a12-42b8-a015-d5c206cb205b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b70e896-0634-4e7b-99d6-8291802a1cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns = ['model','rmse','r2','mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18800b3c-9a73-4644-a724-704ff6bc81a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_levels = round(clothing_data_df.columns.shape[0]*0.5)\n",
    "categorical_features = clothing_data_df.select_dtypes(exclude=[np.number]).columns\n",
    "cats_many = []\n",
    "cats_few = []\n",
    "for ft in categorical_features:\n",
    "    levels = clothing_data_df[ft].unique().shape[0]\n",
    "    if levels > max_levels:\n",
    "        cats_many.append(ft)\n",
    "    else:\n",
    "        cats_few.append(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446fd892-7440-4021-8403-73a8d782e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = clothing_data_df.select_dtypes([np.number]).drop(['price'], axis=1).columns\n",
    "numeric_features\n",
    "\n",
    "categorical_features = clothing_data_df.select_dtypes(exclude=[np.number]).columns\n",
    "categorical_features\n",
    "\n",
    "X = clothing_data_df.drop('price', axis=1)\n",
    "y = clothing_data_df['price']\n",
    "\n",
    "y = np.log(y)\n",
    "\n",
    "X_train, X_test_tmp, y_train, y_test_tmp = train_test_split(X, y, test_size=0.3)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test_tmp, y_test_tmp, test_size=0.5)\n",
    "\n",
    "del X_test_tmp, y_test_tmp\n",
    "\n",
    "selected_model = XGBRegressor(tree_method = \"gpu_hist\",single_precision_histogram=True, gpu_id=0)\n",
    "\n",
    "\n",
    "categorical_transformer_many_level = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('encoder', encoders['BackwardDifferenceEncoder']())\n",
    "    ]\n",
    ")    \n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('encoder', encoders['OneHotEncoder']())\n",
    "    ]\n",
    ") \n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', numeric_transformer, numeric_features),\n",
    "        ('categorical_many', categorical_transformer_many_level, cats_many),\n",
    "        ('categorical', categorical_transformer, cats_few)\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', selected_model)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30738153-6650-41c5-8a8f-7de978bd3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe.named_steps['preprocessor'].fit(X_train)\n",
    "\n",
    "    \n",
    "numeric_feat_names = pipe.named_steps['preprocessor'].transformers_[0][2]\n",
    "cat_feat_names = pipe.named_steps['preprocessor'].transformers_[1][2]\n",
    "#redo_names = pipe.named_steps['preprocessor'].transformers_[2][1].named_steps['encoder'].get_feature_names()\n",
    "#base_names = pipe.named_steps['preprocessor'].transformers_[2][2]   \n",
    "#one_hot_feat_names=[]\n",
    "#for i in range(len(base_names)):\n",
    "#    one_hot_feat_names.append([base_names[i]+'_'+x.split('_')[-1] for x in redo_names if x[0] == str(i)])\n",
    "    \n",
    "feature_names = list(numeric_feat_names) + list(cat_feat_names) #+ [y for x in one_hot_feat_names for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e011dd-0dd4-41b1-87fd-68e8ed483ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
